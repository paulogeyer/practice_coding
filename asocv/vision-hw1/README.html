<h1>CSE 455 Homework 1</h1>
<p>Welcome friends,</p>
<p>It's time for assignment 1! This one may be a little harder than the last one so remember to start early and start often! In order to make grading easier, please only edit the files we mention. You should be able to submit <code>resize_image.c</code> and <code>filter_image.c</code> and we should be able to compile and run them with a fresh clone of the repo without any other files.</p>
<p>To start out this homework, copy over your <code>process_image.c</code> file from hw0 to the <code>src</code> file in this homework. We will be continuing to build out your image library.</p>
<h2>1. Image resizing</h2>
<p>We've been talking a lot about resizing and interpolation in class, now's your time to do it! To resize we'll need some interpolation methods and a function to create a new image and fill it in with our interpolation methods.</p>
<ul>
<li>Fill in <code>float nn_interpolate(image im, float x, float y, int c);</code> in <code>src/resize_image.c</code><ul>
<li>It should perform nearest neighbor interpolation. Remember to use the closest <code>int</code>, not just type-cast because in C that will truncate towards zero.</li>
</ul>
</li>
<li>Fill in <code>image nn_resize(image im, int w, int h);</code>. It should:<ul>
<li>Create a new image that is <code>w x h</code> and the same number of channels as <code>im</code></li>
<li>Loop over the pixels and map back to the old coordinates</li>
<li>Use nearest-neighbor interpolate to fill in the image</li>
</ul>
</li>
</ul>
<p>Now you should be able to run the following <code>python</code> command:</p>
<pre><code>from uwimg import *
im = load_image("data/dogsmall.jpg")
a = nn_resize(im, im.w*4, im.h*4)
save_image(a, "dog4x-nn")
</code></pre>
<p>Your image should look something like:</p>
<p><img alt="blocky dog" src="figs/dog4x-nn.png" /></p>
<p>Finally, fill in the similar functions <code>bilinear_interpolate</code> and <code>bilinear_resize</code> to perform bilinear interpolation. Try it out again in <code>python</code>:</p>
<pre><code>from uwimg import *
im = load_image("data/dogsmall.jpg")
a = bilinear_resize(im, im.w*4, im.h*4)
save_image(a, "dog4x-bl")
</code></pre>
<p><img alt="smooth dog" src="figs/dog4x-bl.png" /></p>
<p>These functions will work fine for small changes in size, but when we try to make our image smaller, say a thumbnail, we get very noisy results:</p>
<pre><code>from uwimg import *
im = load_image("data/dog.jpg")
a = nn_resize(im, im.w//7, im.h//7)
save_image(a, "dog7th-bl")
</code></pre>
<p><img alt="jagged dog thumbnail" src="figs/dog7th-nn.png" /></p>
<p>As we discussed, we need to filter before we do this extreme resize operation!</p>
<h2>2. Image filtering with convolutions</h2>
<p>We'll start out by filtering the image with a box filter. There are very fast ways of performing this operation but instead, we'll do the naive thing and implement it as a convolution because it will generalize to other filters as well!</p>
<h3>2.1 Create your box filter</h3>
<p>Ok, bear with me. We want to create a box filter, which as discussed in class looks like this:</p>
<p><img alt="box filter" src="figs/boxfilter.png" /></p>
<p>One way to do this is make an image, fill it in with all 1s, and then normalize it. That's what we'll do because the normalization function may be useful in the future!</p>
<p>First fill in <code>void l1_normalize(image im)</code>. This should normalize an image to sum to 1.</p>
<p>Next fill in <code>image make_box_filter(int w)</code>. We will only use square box filters so just make your filter <code>w x w</code>. It should be a square image with one channel with uniform entries that sum to 1.</p>
<h3>2.2 Write a convolution function</h3>
<p>Now it's time to fill in <code>image convolve_image(image im, image filter, int preserve)</code>. For this function we have a few scenarios. With normal convolutions we do a weighted sum over an area of the image. With multiple channels in the input image there are a few possible cases we want to handle:</p>
<ul>
<li>If <code>filter</code> and <code>im</code> have the same number of channels then it's just a normal convolution. We sum over spatial and channel dimensions and produce a 1 channel image. UNLESS:</li>
<li>If <code>preserve</code> is set to 1 we should produce an image with the same number of channels as the input. This is useful if, for example, we want to run a box filter over an RGB image and get out an RGB image. This means each channel in the image will be filtered by the corresponding channel in the filter. UNLESS:</li>
<li>If the <code>filter</code> only has one channel but <code>im</code> has multiple channels we want to apply the filter to each of those channels. Then we either sum between channels or not depending on if <code>preserve</code> is set.</li>
</ul>
<p>Also, <code>filter</code> better have either the same number of channels as <code>im</code> or have 1 channel. I check this with an <code>assert</code>.</p>
<p>We are calling this a convolution but you don't need to flip the filter or anything (we're actually doing a cross-correlation). Just apply it to the image as we discussed in class:</p>
<p><img alt="covolution" src="figs/convolution.png" /></p>
<p>Once you are done, test out your convolution by filtering our image! We need to use <code>preserve</code> because we want to produce an image that is still RGB.</p>
<pre><code>from uwimg import *
im = load_image("data/dog.jpg")
f = make_box_filter(7)
blur = convolve_image(im, f, 1)
save_image(blur, "dog-box7")
</code></pre>
<p>We'll get some output that looks like this:</p>
<p><img alt="covolution" src="figs/dog-box7.png" /></p>
<p>Now we can use this to perform our thumbnail operation:</p>
<pre><code>from uwimg import *
im = load_image("data/dog.jpg")
f = make_box_filter(7)
blur = convolve_image(im, f, 1)
thumb = nn_resize(blur, blur.w//7, blur.h//7)
save_image(thumb, "dogthumb")
</code></pre>
<p><img alt="covolution" src="figs/dogthumb.png" /></p>
<p>Look at how much better our new resized thumbnail is!</p>
<p>Resize                     |  Blur and Resize
:-------------------------:|:-------------------------:
<img alt="" src="figs/dog7th-nn.png" />    | <img alt="" src="figs/dogthumb.png" /></p>
<h3>2.2 Make some more filters and try them out!</h3>
<p>Fill in the functions <code>image make_highpass_filter()</code>, <code>image make_sharpen_filter()</code>, and <code>image make_emboss_filter()</code> to return the example kernels we covered in class. Try them out on some images! After you have, answer Question 2.2.1 and 2.2.2 in the source file (put your answer just right there)</p>
<p>Highpass                   |  Sharpen                  | Emboss
:-------------------------:|:-------------------------:|:--------------------|
<img alt="" src="figs/highpass.png" />     | <img alt="" src="figs/sharpen.png" />     | <img alt="" src="figs/emboss.png" /></p>
<h3>2.3 Implement a Gaussian kernel</h3>
<p>Implement <code>image make_gaussian_filter(float sigma)</code> which will take a standard deviation value and return a filter that smooths using a gaussian with that sigma. How big should the filter be, you ask? 99% of the probability mass for a gaussian is within +/- 3 standard deviations so make the kernel be 6 times the size of sigma. But also we want an odd number, so make it be the next highest odd integer from 6x sigma.</p>
<p>We need to fill in our kernel with some values. Use the probability density function for a 2d gaussian:</p>
<p><img alt="2d gaussian" src="figs/2dgauss.png" /></p>
<p>Technically this isn't perfect, what we would really want to do is integrate over the area covered by each cell in the filter. But that's much more complicated and this is a decent estimate. Remember though, this is a blurring filter so we want all the weights to sum to 1. If only we had a function for that....</p>
<p>Now you should be able to try out your new blurring function! It should have much less noise than the box filter:</p>
<pre><code>from uwimg import *
im = load_image("data/dog.jpg")
f = make_gaussian_filter(2)
blur = convolve_image(im, f, 1)
save_image(blur, "dog-gauss2")
</code></pre>
<p><img alt="blurred dog" src="figs/dog-gauss2.png" /></p>
<h2>3. Hybrid images</h2>
<p>Gaussian filters are cool because they are a true low-pass filter for the image. This means when we run them on an image we only get the low-frequency changes in an image like color. Conversely, we can subtract this low-frequency information from the original image to get the high frequency information!</p>
<p>Using this frequency separation we can do some pretty neat stuff. For example, check out <a href="https://petapixel.com/2015/07/08/primer-using-frequency-separation-in-photoshop-for-skin-retouching/">this tutorial on retouching skin</a> in Photoshop (but only if you want to).</p>
<p>We can also make <a href="http://cvcl.mit.edu/hybrid/OlivaTorralb_Hybrid_Siggraph06.pdf">really trippy images</a> that look different depending on if you are close or far away from them. That's what we'll be doing. They are hybrid images that take low frequency information from one image and high frequency info from another. Here's a picture of.... what exactly?</p>
<p>Small                     |  Medium | Large
:-------------------------:|:-------:|:------------------:
<img alt="" src="figs/marilyn-einstein-small.png" />   | <img alt="" src="figs/marilyn-einstein-medium.png" /> | <img alt="" src="figs/marilyn-einstein.png" /></p>
<p>If you don't believe my resizing check out <code>figs/marilyn-einstein.png</code> and view it from far away and up close. Sorta neat, right?</p>
<p>Your job is to produce a similar image. But instead of famous dead people we'll be using famous fictional people! In particular, we'll be exposing the secret (but totally canon) sub-plot of the Harry Potter franchise that Dumbledore is a time-traveling Ron Weasely. Don't trust me?? The images don't lie! Wake up sheeple!</p>
<p>Small                     | Large
:-------------------------:|:------------------:
<img alt="" src="figs/ronbledore-small.jpg" />   | <img alt="" src="figs/ronbledore.jpg" /> </p>
<p>For this task you'll have to extract the high frequency and low frequency from some images. You already know how to get low frequency, using your gaussian filter. To get high frequency you just subtract the low frequency data from the original image.</p>
<p>Fill in <code>image add_image(image a, image b)</code> and <code>image sub_image(image a, image b)</code> so we can perform our transformations. They should probably include some checks that the images are the same size and such. Now we should be able to run something like this:</p>
<pre><code>from uwimg import *
im = load_image("data/dog.jpg")
f = make_gaussian_filter(2)
lfreq = convolve_image(im, f, 1)
hfreq = im - lfreq
reconstruct = lfreq + hfreq
save_image(lfreq, "low-frequency")
save_image(hfreq, "high-frequency")
save_image(reconstruct, "reconstruct")
</code></pre>
<p>Low frequency           |  High frequency | Reconstruction
:-------------------------:|:-------:|:------------------:
<img alt="" src="figs/low-frequency.png" />   | <img alt="" src="figs/high-frequency.png" /> | <img alt="" src="figs/reconstruct.png" /></p>
<p>Note, the high-frequency image overflows when we save it to disk? Is this a problem for us? Why or why not?</p>
<p>Use these functions to recreate your own Ronbledore image. You will need to tune your standard deviations for the gaussians you use. You will probably need different values for each image to get it to look good.</p>
<h2>4. Sobel filters</h2>
<p>The <a href="https://www.researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator">Sobel filter</a> is cool because we can estimate the gradients and direction of those gradients in an image. They should be straightforward now that you all are such pros at image filtering.</p>
<h3>4.1 Make the filters</h3>
<p>First implement the functions to make our sobel filters. They are for estimating the gradient in the x and y direction:</p>
<p>Gx                 |  Gy 
:-----------------:|:------------------:
<img alt="" src="figs/gx.png" />   |  <img alt="" src="figs/gy.png" /></p>
<h3>4.2 One more normalization...</h3>
<p>To visualize our sobel operator we'll want another normalization strategy, <a href="https://en.wikipedia.org/wiki/Feature_scaling">feature normalization</a>. This strategy is simple, we just want to scale the image so all values lie between [0-1]. In particular we will be <a href="https://en.wikipedia.org/wiki/Feature_scaling#Rescaling">rescaling</a> the image by subtracting the minimum from all values and dividing by the range of the data. If the range is zero you should just set the whole image to 0 (don't divide by 0 that's bad).</p>
<h3>4.3 Calculate gradient magnitude and direction</h3>
<p>Fill in the function <code>image *sobel_image(image im)</code>. It should return two images, the gradient magnitude and direction. The strategy can be found <a href="https://en.wikipedia.org/wiki/Sobel_operator#Formulation">here</a>. We can visualize our magnitude using our normalization function:</p>
<pre><code>from uwimg import *
im = load_image("data/dog.jpg")
res = sobel_image(im)
mag = res[0]
feature_normalize(mag)
save_image(mag, "magnitude")
</code></pre>
<p>Which results in:</p>
<p><img alt="" src="figs/magnitude.png" /></p>
<h3>4.4 Make a colorized representation</h3>
<p>Now using your sobel filter try to make a cool, stylized one. Fill in the function <code>image colorize_sobel(image im)</code>. I used the magnitude to specify the saturation and value of an image and the angle to specify the hue but you can do whatever you want (as long as it looks cool). I also used some smoothing:</p>
<p><img alt="" src="figs/lcolorized.png" /></p>
<h2>5. Turn it in</h2>
<p>Turn in your <code>resize_image.c</code>, <code>filter_image.c</code>, <code>ronbledore.jpg</code> and <code>sobel.jpg</code> on canvas under Assignment 1.</p>